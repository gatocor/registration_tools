{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Datasets\n",
    "This notebook demonstrates how to create artificial datasets, load datasets and manipulate them.\n",
    "\n",
    "## Index\n",
    "1. [Import the corresponding libraries](#Import-the-corresponding-libraries)\n",
    "2. [Create an artificial dataset of spherical images](#Create-an-artificial-dataset-of-spherical-images)\n",
    "3. [Visualizing](#Visualizing)\n",
    "4. [Make video](#Make-video)\n",
    "5. [Register the images](#Register-the-images)\n",
    "6. [Check the correction of the registered images](#Check-the-correction-of-the-registered-images)\n",
    "7. [Make videos](#Make-videos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formats of Input Datasets\n",
    "\n",
    "Usually datasets are found in the following formats:\n",
    "\n",
    " - **Separate files distributed over folders**. Usually, datasets coming from a microscope machine have the following structure:\n",
    "\n",
    "        - dataset\n",
    "            - ch1\n",
    "                - file_t1.tif\n",
    "                - file_t2.tif\n",
    "                - ...\n",
    "            - ch2\n",
    "                - file_t1.tif\n",
    "                - file_t2.tif\n",
    "                - ...\n",
    "\n",
    " - **Numpy Arrays**: Used for small datasets. \n",
    " - **[zarr](https://zarr.readthedocs.io/en/stable/)**: Format for efficient batch loading and distribution of big datasets.\n",
    " - **h5/h5f**: Similar to zarr, it is a format for efficient manipulation of datasets.\n",
    "\n",
    "In the following we will create an artificial dataset and see how to open it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an artificial dataset\n",
    "\n",
    "We are going to generate an artificial dataset and then we will load it. \n",
    " - `registration_tools.data` contains functions to generate artificial datasets to test.\n",
    " - `registation_tools.dataset` contains functions to load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import registration_tools.data as rt_data #For generating artificial datasets\n",
    "import registration_tools.dataset as rt_dataset #For generating artificial datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide a folder, the dataset will generate a folder structure in separated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = rt_data.sphere(\n",
    "#     out='dataset_sphere',\n",
    "#     num_channels=3,\n",
    "#     image_size=100,  #This indicates to make an image of size image_size x image_size x image_size\n",
    "#     stride=(1,1,2),  #This to downsample the image by a factor of stride per dimension\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the structure of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- channel_0\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n",
      "|-- channel_1\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n",
      "|-- channel_2\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n"
     ]
    }
   ],
   "source": [
    "rt_dataset.show_dataset_structure('dataset_sphere')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the metainformation of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset of separated files\n",
    "\n",
    "Now we can load this folder structure as an object Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(shape=(3, 10, 100, 100, 50), axis=CTXYZ, scale=(1, 1, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = rt_dataset.Dataset(\n",
    "    [\n",
    "        \"dataset_sphere/channel_0/sphere_{:02d}.tiff\",\n",
    "        \"dataset_sphere/channel_1/sphere_{:02d}.tiff\",\n",
    "        \"dataset_sphere/channel_2/sphere_{:02d}.tiff\",\n",
    "    ],\n",
    "    axis_data=\"CT\",\n",
    "    axis_files=\"XYZ\",\n",
    "    scale=(1,1,2)      # Scale of the dataset, is the same as the stride in the generation\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to zarr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an artificial dataset of spherical images\n",
    "We will create an artifitcial dataset of 10 spherical images with 3 channels.\n",
    "\n",
    "By default, if a path is not specified, it will return a [zarr array](https://zarr.readthedocs.io/en/stable/user-guide/). This data type is great for storing big datasets in an eficient way and allow to upload data in memory by batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'zarr.core.array.Array'>\n",
      "Shape:  TCZYX\n",
      "Scale:  (1, 1, 1)\n",
      "Shape:  (10, 3, 50, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset of spherical images\n",
    "dataset = rt_data.sphere(\n",
    "    out = None, #If not specified, a new dataset is created and stored in RAM\n",
    "    num_images=10,\n",
    "    image_size=50,\n",
    "    num_channels=3,\n",
    "    min_radius=5,\n",
    "    max_radius=5,\n",
    "    jump=2,\n",
    "    stride=(1, 1, 1)\n",
    ")\n",
    "print(\"Type: \", type(dataset))\n",
    "print(\"Shape: \", dataset.attrs[\"axis\"])\n",
    "print(\"Scale: \", dataset.attrs[\"scale\"])\n",
    "print(\"Shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing\n",
    "\n",
    "Initialize the napari viewer to visualize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the napari viewer\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and load the dataset to napari. The package provides some helpful functions to plot images generated during the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images in the dataset\n",
    "viewer.layers.clear() #Clear the viewer of other layers that may be present\n",
    "rt_vis.add_image_difference(viewer, dataset)\n",
    "rt_vis.add_image_difference(viewer, dataset)\n",
    "# viewer.add_image(dataset, scale=dataset.attrs[\"scale\"]) #This would have been equivalent to the above line.\n",
    "viewer.dims.ndisplay = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video\n",
    "\n",
    "There is a convenient function to create videos from the current display in the napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make video\n",
    "rt_vis.make_video(\n",
    "    viewer=viewer,\n",
    "    save_file='sphere_dataset.gif',\n",
    "    fps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the images\n",
    "Register the images in the dataset to correct for any misalignments.\n",
    "\n",
    "First we generate the registration model. There are a few parameters to take into account:\n",
    "\n",
    " 1. Pyramid levels. This indicates the coarse graining (block sizes) that will be used to register the images. The lower the number the smaller the blocks (0 will be pixel size). Smaller numbers will capture finer details but will be slower too. \n",
    " 2. Type of transformation (translation, registration, vectorfield...)\n",
    " 3. Direction of registration (backward means finding a tranformation from future to past t+1 -> t)\n",
    " 4. If to perform global transformation. That is, generate a set of transformations between t -> 0. In our case, since we just want to correct for the movement, we will set it to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the video\n",
    "registration = rt_reg.Registration(\n",
    "    pyramid_highest_level=3,           #Higher pyramid level\n",
    "    pyramid_lowest_level=0,            #Lower pyramid level\n",
    "    registration_type='translation',   #Type of registration\n",
    "    registration_direction='backward', #Direction of registration\n",
    "    perfom_global_trnsf=True           #Whether to perform global transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we apply it to the dataset. We use fit_apply to:\n",
    "\n",
    " 1. Get the transformations.\n",
    " 2. Apply the transformations to the dataset. \n",
    "\n",
    "The registration method can only work with one channel. If the data has different channels, you should specify which channel it should use for registering the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering images using channel 0: 100%|██████████| 9/9 [00:00<00:00, 141.06/s]\n",
      "Applying registration to images: 100%|██████████| 9/9 [00:00<00:00, 192.57/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_registered = registration.fit_apply(    \n",
    "    dataset=dataset,\n",
    "    use_channel=0,     #Which channel to use for the registration.\n",
    "    out=None,          #If not specified, a new dataset is created and stored in RAM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the correction of the registered images\n",
    "\n",
    "For that, we plot the original dataset and the registered one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make video projections\n",
    "viewer.layers.clear() # Clear the viewer from past images\n",
    "rt_vis.add_image(viewer, dataset[0], name=\"t0\")\n",
    "rt_vis.add_image(viewer, dataset, name=\"dataset\", colormap=\"red\")\n",
    "rt_vis.add_image(viewer, dataset_registered, opacity=0.5, colormap='green', name=\"dataset_registered\")\n",
    "viewer.dims.ndisplay = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make videos\n",
    "\n",
    "Now that we checked that the correction is satisfactory, we can save the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make video registered\n",
    "rt_vis.make_video(\n",
    "    viewer=viewer,\n",
    "    save_file='sphere_dataset_registered.gif',\n",
    "    fps=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "registration_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
