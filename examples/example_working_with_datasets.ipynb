{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "## Index\n",
    "1. [Types of allowed data](#Types-of-allowed-data)\n",
    "2. [Working with Datasets Structure](#Working-with-Datasets-Structure)\n",
    "3. [Creating an artificial Dataset](#Creating-an-artificial-Dataset)\n",
    "4. [Loading a dataset of separated files](#Loading-a-dataset-of-separated-files)\n",
    "5. [Converting to zarr](#Converting-to-zarr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of allowed data\n",
    "\n",
    "The basic formats allowed are indexed arrays as:\n",
    "\n",
    " - numpy arrays\n",
    " - zarr arrays\n",
    " - h5/h5f files\n",
    " - separated files inside folders (see next section)\n",
    "\n",
    "where we have zarr as the basic input array for its efficient manipulation using batches of data. You can upload it in any way you want. however, we also provide a function 'load_dataset' to read it that helps to make sure you upload it in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import registration_tools.dataset as rt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a random dataset with 4 timepoints, 3 channels, and 10x10x10 images\n",
    "dataset = np.random.rand(4,3,10,10,10)\n",
    "#Save the dataset to a file\n",
    "np.save('dataset.npy', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset structure and ensure that necessary attributes are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (4, 3, 10, 10, 10)\n",
      "Attributes not found.\n"
     ]
    }
   ],
   "source": [
    "rt_dataset.check_dataset_structure(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can upload with load dataset instead to make sure all necessary attributes for many functions are found.\n",
    "\n",
    "**Note: This does not mean that you cannot work with this data. Simnply that mostly sure this data will be asked later on for some function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (4, 3, 10, 10, 10)\n",
      "Axis:  TCZYX\n",
      "Scale:  (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = rt_dataset.load_dataset(\n",
    "    'dataset.npy',\n",
    "    axis=\"TCZYX\",\n",
    "    scale=(1,1,1),\n",
    ")\n",
    "\n",
    "rt_dataset.check_dataset_structure(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Datasets Structure\n",
    "\n",
    "Usually datasets are found in separate files distributed over folders. Usually, datasets coming from a microscope machine have structures similar to\n",
    "\n",
    "        - dataset\n",
    "            - ch1\n",
    "                - file_t1.tif\n",
    "                - file_t2.tif\n",
    "                - ...\n",
    "            - ch2\n",
    "                - file_t1.tif\n",
    "                - file_t2.tif\n",
    "                - ...\n",
    "\n",
    "In this example we show how to create the data structure `Dataset` to work with this format of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an artificial Dataset\n",
    "\n",
    "We are going to generate an artificial dataset and then we will load it. \n",
    " - `registration_tools.data` contains functions to generate artificial datasets to test.\n",
    " - `registation_tools.dataset` contains functions to load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import registration_tools.data as rt_data #For generating artificial datasets\n",
    "import registration_tools.dataset as rt_dataset #For generating artificial datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide a folder, the dataset will generate a folder structure in separated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rt_data.sphere(\n",
    "    out='dataset_sphere',\n",
    "    num_channels=3,\n",
    "    image_size=100,  #This indicates to make an image of size image_size x image_size x image_size\n",
    "    stride=(1,1,2),  #This to downsample the image by a factor of stride per dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the structure of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- channel_0\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n",
      "|-- channel_1\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n",
      "|-- channel_2\n",
      "    |-- sphere_00.tiff\n",
      "    |-- sphere_01.tiff\n",
      "    |-- sphere_02.tiff\n",
      "    |-- ...\n",
      "    |-- sphere_07.tiff\n",
      "    |-- sphere_08.tiff\n",
      "    |-- sphere_09.tiff\n"
     ]
    }
   ],
   "source": [
    "rt_dataset.show_dataset_structure('dataset_sphere')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a dataset of separated files\n",
    "\n",
    "Now we can load this folder structure as an object Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(shape=(3, 10, 100, 100, 50), axis=CTXYZ, scale=(1, 1, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = rt_dataset.Dataset(\n",
    "    [\n",
    "        \"dataset_sphere/channel_0/sphere_{:02d}.tiff\",\n",
    "        \"dataset_sphere/channel_1/sphere_{:02d}.tiff\",\n",
    "        \"dataset_sphere/channel_2/sphere_{:02d}.tiff\",\n",
    "    ],\n",
    "    axis_data=\"CT\",\n",
    "    axis_files=\"XYZ\",\n",
    "    scale=(1,1,2)      # Scale of the dataset, is the same as the stride in the generation\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to zarr\n",
    "\n",
    "You can work with this Dataset for most of the functions afterwards. However you may be interested in converting it to a zarr array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving to Zarr:   0%|          | 0/30 [00:00<?, ?images/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving to Zarr: 100%|██████████| 30/30 [00:00<00:00, 74.52images/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.to_zarr(\"dataset_spheres.zarr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
